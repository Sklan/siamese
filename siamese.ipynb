{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "siamese.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sklan/siamese/blob/master/siamese.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "LKT5h0i0_h4y",
        "colab_type": "code",
        "outputId": "180534a0-fbf1-4584-c45d-4944495aecf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        }
      },
      "cell_type": "code",
      "source": [
        "! pip install tf-nightly-2.0-preview"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tf-nightly-2.0-preview\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/06/4e6cb0ebd0a9d95e9bee2ef084fe6ebb0afaae4676757d6fb6a46205c33f/tf_nightly_2.0_preview-2.0.0.dev20190321-cp36-cp36m-manylinux1_x86_64.whl (80.3MB)\n",
            "\u001b[K    100% |████████████████████████████████| 80.3MB 357kB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (0.33.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (1.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (1.14.6)\n",
            "Collecting google-pasta>=0.1.2 (from tf-nightly-2.0-preview)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8c/96/adbd4eafe72ce9b5ca6f168fbf109386e1b601f7c59926a11e9d7b7a5b44/google_pasta-0.1.4-py3-none-any.whl (51kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 21.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (3.7.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (1.11.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (0.7.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (1.0.9)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (0.7.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (1.0.7)\n",
            "Collecting tensorflow-estimator-2.0-preview (from tf-nightly-2.0-preview)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/95/f6bfcb8cfdac12287c8649cbdc2cb1be8890a9c6bd624fb5cb784bdd2c18/tensorflow_estimator_2.0_preview-1.14.0.dev2019032100-py2.py3-none-any.whl (351kB)\n",
            "\u001b[K    100% |████████████████████████████████| 358kB 19.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview) (0.2.2)\n",
            "Collecting tb-nightly<1.15.0a0,>=1.14.0a0 (from tf-nightly-2.0-preview)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5d/17/a3d05a0664c11703259aa79d2b58b871b3bb1fff24153f75db04540489db/tb_nightly-1.14.0a20190319-py3-none-any.whl (3.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 3.0MB 1.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tf-nightly-2.0-preview) (40.8.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tf-nightly-2.0-preview) (2.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a0,>=1.14.0a0->tf-nightly-2.0-preview) (3.0.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a0,>=1.14.0a0->tf-nightly-2.0-preview) (0.14.1)\n",
            "Installing collected packages: google-pasta, tensorflow-estimator-2.0-preview, tb-nightly, tf-nightly-2.0-preview\n",
            "Successfully installed google-pasta-0.1.4 tb-nightly-1.14.0a20190319 tensorflow-estimator-2.0-preview-1.14.0.dev2019032100 tf-nightly-2.0-preview-2.0.0.dev20190321\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "43U3biHO8qXy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import offsetbox\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.layers import Layer\n",
        "\n",
        "from sklearn.preprocessing import normalize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xwIMWS4HwDPM",
        "colab_type": "code",
        "outputId": "03c49456-b9ff-44d9-e0d2-e1bfad6d4b0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "tf.enable_eager_execution()\n",
        "tf.executing_eagerly() "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "AcITKWinqeOo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_classes = 10\n",
        "epochs = 500\n",
        "batch_size = 256\n",
        "steps = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YHUS1rDPTvtw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mnist = tfds.load(name=\"mnist\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "40qiQzPgUt3N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train, test = mnist['train'], mnist['test']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VwnqKTlVVPk_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_iterator = train.repeat().shuffle(1024).batch(batch_size).__iter__()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OV5Nb2C-6QjX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def preprocess(x):\n",
        "  x = tf.reshape(x, (-1, 784))\n",
        "  x = tf.cast(x, tf.float32)\n",
        "  x = tf.divide(x, 255.)\n",
        "  return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_j6r1cEExOOh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def contrastive_loss(model, x, y):\n",
        "  # If you look carefully the implemented formula is slightly different from the Hadsell'06 paper.\n",
        "  distance = model(x)\n",
        "  margin = 5.\n",
        "  similarity = tf.multiply(y, tf.pow(distance, 2))\n",
        "  dissimilarity = tf.multiply(tf.subtract(1.0, y), tf.pow(tf.maximum(0.0, margin - distance), 2))\n",
        "  loss = tf.reduce_mean(tf.multiply(tf.add(similarity, dissimilarity), .5)) \n",
        "  return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_bVygOpjPx0s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate_pairs(iterator, steps):\n",
        "  i = 0\n",
        "  while i < steps:\n",
        "    feature = iterator.next()\n",
        "    x1 = preprocess(feature['image'])\n",
        "    y1 = feature['label']\n",
        "    feature = iterator.next()\n",
        "    x2 = preprocess(feature['image'])\n",
        "    y2 = feature['label']\n",
        "    y = tf.cast(tf.equal(y1, y2), tf.float32)\n",
        "    i = i + 1\n",
        "    yield [x1, x2], y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N5xShjsIkZkP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def visualize(embed, x_test, y_test):\n",
        "  # From https://github.com/ywpkwon/siamese_tf_mnist\n",
        "    feat = embed\n",
        "    ax_min = np.min(embed,0)\n",
        "    ax_max = np.max(embed,0)\n",
        "    ax_dist_sq = np.sum((ax_max - ax_min)**2)\n",
        "\n",
        "    plt.figure()\n",
        "    ax = plt.subplot(111)\n",
        "    colormap = plt.get_cmap('tab10')\n",
        "    shown_images = np.array([[1., 1.]])\n",
        "    for i in range(feat.shape[0]):\n",
        "        dist = np.sum((feat[i] - shown_images)**2, 1)\n",
        "        if np.min(dist) < 3e-4*ax_dist_sq:   # don't show points that are too close\n",
        "            continue\n",
        "        shown_images = np.r_[shown_images, [feat[i]]]\n",
        "        patch_to_color = np.expand_dims(x_test[i], -1)\n",
        "        patch_to_color = np.tile(patch_to_color, (1, 1, 3))\n",
        "        patch_to_color = (1-patch_to_color) * (1,1,1) + patch_to_color * colormap(y_test[i]/10.)[:3]\n",
        "        imagebox = offsetbox.AnnotationBbox(\n",
        "            offsetbox.OffsetImage(patch_to_color, zoom=0.5, cmap=plt.cm.gray_r),\n",
        "            xy=feat[i], frameon=False\n",
        "        )\n",
        "        ax.add_artist(imagebox)\n",
        "\n",
        "    plt.axis([ax_min[0], ax_max[0], ax_min[1], ax_max[1]])\n",
        "    plt.title('Embedding from the last layer of the network')\n",
        "    plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-GGpUO6hZEMB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Siamese(Model):\n",
        "  def __init__(self):\n",
        "    super(Siamese, self).__init__()\n",
        "    self.dense_left1 = layers.Dense(512, activation='relu',\n",
        "                                      kernel_initializer='glorot_uniform',\n",
        "                                      bias_initializer='glorot_uniform')\n",
        "    self.dense_left2 = layers.Dense(512, activation='relu',\n",
        "                                      kernel_initializer='glorot_uniform',\n",
        "                                      bias_initializer='glorot_uniform')\n",
        "    self.dense_left3 = layers.Dense(512, activation='relu',\n",
        "                                      kernel_initializer='glorot_uniform',\n",
        "                                      bias_initializer='glorot_uniform')\n",
        "    self.dense_left4 = layers.Dense(512, activation='relu',\n",
        "                                      kernel_initializer='glorot_uniform',\n",
        "                                      bias_initializer='glorot_uniform')\n",
        "    self.dense_left5 = layers.Dense(2, \n",
        "                                      activation='sigmoid',\n",
        "                                      kernel_initializer='glorot_uniform',\n",
        "                                      bias_initializer='glorot_uniform')\n",
        "   \n",
        "\n",
        "    self.dense_right1 = layers.Dense(512, activation='relu',\n",
        "                                      kernel_initializer='glorot_uniform',\n",
        "                                      bias_initializer='glorot_uniform') \n",
        "    self.dense_right2 = layers.Dense(512, activation='relu',\n",
        "                                      kernel_initializer='glorot_uniform',\n",
        "                                      bias_initializer='glorot_uniform')\n",
        "    self.dense_right3 = layers.Dense(512, activation='relu',\n",
        "                                      kernel_initializer='glorot_uniform',\n",
        "                                      bias_initializer='glorot_uniform')\n",
        "    self.dense_right4 = layers.Dense(512, activation='relu',\n",
        "                                      kernel_initializer='glorot_uniform',\n",
        "                                      bias_initializer='glorot_uniform')\n",
        "    self.dense_right5 = layers.Dense(2, activation='sigmoid',\n",
        "                                      kernel_initializer='glorot_uniform',\n",
        "                                      bias_initializer='glorot_uniform')\n",
        "    \n",
        "    self.a = None\n",
        "    self.b = None\n",
        "    self.x = None\n",
        "    self.y = None\n",
        "    \n",
        "  def call(self, inputs):\n",
        "    self.a, self.b = inputs\n",
        "    z = self.dense_left1(self.a)\n",
        "    z = self.dense_left2(z)\n",
        "    z = self.dense_left3(z)\n",
        "    z = self.dense_left4(z)\n",
        "    self.x = self.dense_left5(z)\n",
        "\n",
        "    z = self.dense_right1(self.b)\n",
        "    z = self.dense_right2(z)\n",
        "    z = self.dense_right3(z)\n",
        "    z = self.dense_right4(z)\n",
        "    self.y = self.dense_right5(z)\n",
        "    \n",
        "    # Calculate the Euclidean Distance\n",
        "    distance = tf.sqrt(tf.reduce_sum(tf.pow(tf.subtract(self.x, self.y), 2), axis=1, keepdims=True))\n",
        "    \n",
        "    return distance\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mH7vVmfPdDYO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Siamese()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8v9dkTfPP2R-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def grad(model, inputs, targets):\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss_value = contrastive_loss(model, inputs, targets)\n",
        "  return loss_value, tape.gradient(loss_value, model.trainable_variables)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RLEjtITPnrh4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learning_rate = tf.constant(0.00001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N1UNZLWNlZsh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = tf.optimizers.SGD(learning_rate, momentum=0.0001, nesterov=True)\n",
        "global_step = tf.Variable(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "grUR0eic99Lc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "  x, y = None, None\n",
        "  for x, y in generate_pairs(train_iterator, steps) :\n",
        "    loss_value, grads = grad(model, x, y)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables), global_step)\n",
        "  print('Epoch:', epoch, 'loss:', loss_value.numpy())\n",
        "  if epoch % 50 == 0:\n",
        "    em = model.x.numpy()\n",
        "    x = np.reshape(x[0], (-1, 28, 28))\n",
        "    visualize(em, x, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8PzpdIjrziD8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}